<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>DOOCN-XIII: Dynamics On and Of Complex Networks</title>
  <meta name="description" content="Official website of the Dynamics On and Of Complex Networks workshop series">

  <link rel="stylesheet" type="text/css" href="semantic.min.css">

  <style>
  body {
    line-height: 1.5em;
    background-image: url("images/background.png");
  }
  #root {
    margin-top: 1em;
    margin-bottom: 1em;
  }
  .monospaced {
    font-family: "Courier New", Courier, monospace;
    font-weight: bold;
  }
  .push-down {
    padding-top: 0.7rem;
  }
  .people-container-2colmax {
    max-width: 580px;
    margin: 0 auto;
  }
  h1 {
    font-size: 1.8rem;
    text-align: center;
  }
  h2 {
    font-size: 1.5rem;
    text-align: center;
  }
  h3 {
    font-size: 1.5rem;
  }
  h4 {
    margin-top: 0.5rem;
    margin-bottom: 1rem;
    font-size: 1.2rem;
  }
  p.location {
    text-align: center;
    font-weight: normal;
    font-style: italic;
  }
  p {
    text-align: justify;
  }
  ul li {
    margin-bottom: 1em;
  }
  </style>
</head>

<body>
<div id="root" class="ui container">

<h1>DOOCN-XIII: Network Learning</h1>
<h2>Dynamics On and Of Complex Networks 2020</h2>

<p>The Dynamics On and Of Complex Networks (DOOCN) workshop series,
aims on exploring statistical dynamics on and of complex networks.
<em>Dynamics on networks</em> refers to the different types of
processes that take place on networks,
like spreading, diffusion, and synchronization.
Modeling such processes is strongly affected by the topology
and temporal variation of the network structure,
i.e., by the <em>dynamics of networks</em>.
Recently, machine learning techniques have been used
to model dynamics of massively large complex networks
generated from big data,
and the various functionalities resulting from the networks.
This motivates us to focus on
<strong>&ldquo;Network Learning&rdquo;</strong>
as the significant topic of interest in the 2020 edition.</p>

<p>As Machine Learning and Deep Neural Networks have become increasingly popular,
researchers in Network Science have adopted its tools
to explore and study graphs and networks.
Graph Embedding or Network Representation Learning is one such tool
that aims to compute vector space representations
of nodes and edges of a network,
that capture their relations semantically.
Similarly Deep Neural Networks are being extensively used
in developing graph generative models
with the idea being a model trained on a graph of specific type
is able to generate graphs of similar types
without the explicit information of the underlying mechanism of edge formation.
Additionally, Deep Neural Network models have also been demonstrated
to be better equipped at link prediction
thereby expanding the repertoire of tools available
for studying network evolution.
We dub these areas of related research areas together as
<strong>&ldquo;Network Learning&rdquo;</strong>.

<p>The 13<sup>th</sup> edition of the DOOCN workshop,
&ldquo;DOOCN-XIII: Network Learning&rdquo; will be held on <strong>September 18, 2020</strong>
in conjunction with the upcoming
<a href="https://netsci2020.netscisociety.net/">NetSci 2020</a> conference
which will take place during 17&ndash;25 September 2020, in Rome, Italy (Online).
</p>

<p><em>Due to the ongoing COVD-19 situation the NetSci 2020
  along with DOOCN-XIII will be held online.</em></p>

<div id="navbar" class="ui five item stackable menu">
  <a href="#invited" class="item">Invited Speakers</a>
  <a href="#organizers" class="item">Organizers</a>
  <a href="#program" class="item">Program</a>
  <a href="#history" class="item">History</a>
  <a href="#books" class="item">DOOCN Book Series</a>
</div>

<h3 id="invited">Invited Speakers</h3>

<div class="ui cards">
  <a href="http://jlguillaume.free.fr/www/" class="ui centered card">
    <div class="image">
      <img src="images/guillaume.jpg">
    </div>
    <div class="content">
      <div class="header">Jean-Loup Guillaume</div>
      <div class="description">University of La Rochelle, France</div>
    </div>
  </a>
  <a href="https://www.professoren.tum.de/en/guennemann-stephan/" class="ui centered card">
    <div class="image">
      <img src="images/guennemann-cropped.jpg">
    </div>
    <div class="content">
      <div class="header">Stephan Günnemann</div>
      <div class="description">Technical University of Munich, Germany</div>
    </div>
  </a>
  <a href="http://mediamining.univ-lyon2.fr/velcin/" class="ui centered card">
    <div class="image">
      <img src="images/velcin.jpg">
    </div>
    <div class="content">
      <div class="header">Julien Velcin</div>
      <div class="description">University of Lyon, France</div>
    </div>
  </a>
  <a href="http://perso.ens-lyon.fr/marton.karsai/" class="ui centered card">
    <div class="image">
      <img src="images/karsai-cropped.jpg">
    </div>
    <div class="content">
      <div class="header">Márton Karsai</div>
      <div class="description">Central European University, Austria</div>
    </div>
  </a>
  <a href="http://web.stanford.edu/~chami/" class="ui centered card">
    <div class="image">
      <img src="images/chami-cropped.jpg">
    </div>
    <div class="content">
      <div class="header">Ines Chami</div>
      <div class="description">Stanford University, USA</div>
    </div>
  </a>
</div>

<h3 id="program">Program</h3>

<ul>
    <li><span class="monospaced">13:00&ndash;13:10</span>: Welcome and introductions</li>

    <li><span class="monospaced">13:10&ndash;13:50</span>:
      Invited Talk by <strong>Jean-Loup&nbsp;Guillaume</strong>
      <h4>Title: Scalable Network Embedding</h4>
      <p>Abstract:
      Network embedding consists in mapping the nodes of a graph in a low-dimensional space in order to preserve the topological structure of the network. These embedded vectors can then be used as features for various network mining tasks. Although most existing network embedding approaches use random walks, matrix factorization, or deep learning techniques to represent nodes, they are generally computationally expensive and cannot be used on large networks with billions of edges.</p>

      <p>In this talk, I will first present the different network embedding solutions, and then I will detail LouvainNE, an embedding technique that uses a hierarchical clustering approach.  This solution builds a hierarchy of communities and a representation of the individual nodes in the original graph at different levels of the hierarchy which are then aggregated into the final vectors. I will show that this solution has a quasi linear runtime and a memory complexity in practice that allows it to process graphs containing tens of billions of edges. It is also very efficient for performing classical network exploration tasks such as network reconstruction and node classification.</p>
    </li>

    <li><span class="monospaced">13:50&ndash;14:10</span>: QnA and Break</li>

    <li><span class="monospaced">14:10&ndash;14:50</span>:
      Invited Talk by <strong>Julien&nbsp;Velcin</strong>
      <h4>Title: Recent Advances in Document Network Embedding</h4>
      <p>Abstract:
Many sources of our informational landscape can be formalized as a document network (e.g., scientific papers, social media). For a long time the textual content of documents and the structure that encodes how documents relate to each other have been considered separately. Recently, document network embedding has been proposed to learn representations that take both content and structure into account. The new vector space can then be used for downstreams tasks, such as classification or link prediction. In this talk I will give an overview of recent methods that aim at building such embedding space. In particular, I will focus on several models that were recently proposed in the ERIC Lab.</p>
    </li>

    <li><span class="monospaced">14:50&ndash;15:10</span>: QnA and Break</li>

    <li><span class="monospaced">15:10&ndash;15:50</span>:
      Invited Talk by <strong>Stephan&nbsp;Günnemann</strong>
      <h4>Title: Can you trust your GNN? &ndash; Adversarial Robustness of Machine Learning Models for Graphs</h4>
      <p>Abstract:
Graph neural networks have recently achieved impressive results in many
graph learning tasks. Despite their proliferation, studies of their
robustness properties are still very limited &ndash; yet, in domains where
graph learning methods are often used, e.g. the web, adversaries are
common. In my talk, I will shed light on the aspect of adversarial
robustness for state-of-the art graph-based learning techniques. I will
highlight the unique challenges and opportunities that come along with
the graph setting and I will introduce perturbation approaches
showcasing the methods vulnerabilities. I will conclude with a
discussion of robustness certificates as well a learning principles for
improving robustness.</p>
    </li>

    <li><span class="monospaced">15:50&ndash;16:10</span>: QnA and Break</li>

    <li><span class="monospaced">16:10&ndash;16:50</span>:
      Invited Talk by <strong>Márton&nbsp;Karsai</strong>
      <h4>Title: Weg2Vec: Event Embedding for Temporal Networks</h4>
      <p>Abstract:
Network embedding techniques are powerful to capture structural regularities in networks and to identify similarities between their local fabrics. However, conventional network embedding models are developed for static structures, commonly consider nodes only and they are seriously challenged when the network is varying in time. Temporal networks may provide an advantage in the description of real systems, but they code more complex information, which could be effectively represented only by a handful of methods so far. In this talk we introduce a new method of event embedding of temporal networks, called weg2vec, which builds on temporal and structural similarities of events to learn a low dimensional representation of a temporal network. This projection successfully captures latent structures and similarities between events involving different nodes at different times and provides ways to predict the final outcome of spreading processes unfolding on the temporal structure.</p>
    </li>

    <li><span class="monospaced">16:50&ndash;17:10</span>: QnA and Break</li>

    <li><span class="monospaced">17:10&ndash;17:40</span>:
      Invited Talk by <strong>Ines&nbsp;Chami</strong>
      <h4>Title: Low-dimensional hyperbolic embeddings of graphs: methods and applications.</h4>
      <p>Abstract:
Graph embedding methods aim at learning representations of nodes that preserve graph properties (e.g. graph distances). These embeddings can then be used in downstream applications such as recommendation systems. Most machine learning algorithms learn embeddings into the standard Euclidean space. Recent research shows promise for more faithful embeddings by leveraging non-Euclidean geometries, such as hyperbolic or spherical geometries. In particular, trees can be embedded almost perfectly into hyperbolic space, while this is not possible in standard Euclidean space. In this talk, we review basic notions of hyperbolic geometry and then go over machine learning algorithms that learn embeddings into hyperbolic space. We cover recent applications of such embeddings ranging from gradient-based Hierarchical Clustering to link prediction in Knowledge Graphs.</p>
    </li>

    <li><span class="monospaced">17:40&ndash;18:00</span>: QnA and Closing</li>

</ul>

<h3 id="organizers">Organizers</h3>

<div class="ui cards">
  <a href="https://sites.google.com/site/fakhtehghanbarnejad/" class="ui centered card">
    <div class="image">
      <img src="images/ghanbarnejad.jpg">
    </div>
    <div class="content">
      <div class="header">Fakhteh Ghanbarnejad</div>
      <div class="description">Sharif University of Technology (SUT), Tehran, Iran</div>
    </div>
  </a>
  <a href="http://parantapa.net/" class="ui centered card">
    <div class="image">
      <img src="images/bhattacharya.jpg">
    </div>
    <div class="content">
      <div class="header">Parantapa Bhattacharya</div>
      <div class="description">University of Virginia, USA</div>
    </div>
  </a>
  <a href="https://sites.google.com/view/sandipanscssh/" class="ui centered card">
    <div class="image">
      <img src="images/sikdar-cropped.jpg">
    </div>
    <div class="content">
      <div class="header">Sandipan Sikdar</div>
      <div class="description">RWTH Aachen, Germany</div>
    </div>
  </a>
  <a href="https://camilleroth.github.io/" class="ui centered card">
    <div class="image">
      <img src="images/roth-cropped.jpg">
    </div>
    <div class="content">
      <div class="header">Camille Roth</div>
      <div class="description">CNRS France / Centre Marc Bloch, Germany</div>
    </div>
  </a>
  <a href="http://people.mpi-inf.mpg.de/~pramanik/" class="ui centered card">
    <div class="image">
      <img src="images/pramanik-cropped.jpg">
    </div>
    <div class="content">
      <div class="header">Soumajit Pramanik</div>
      <div class="description">Max Planck Institute for Informatics, Germany</div>
    </div>
  </a>
</div>

<h3 id="history">History</h3>

<p>The first Dynamics On and Of Complex Networks (DOOCN I)
took place in Dresden, Germany, on 4th October 2007,
as a satellite workshop of the European Conference on Complex Systems 07.
The workshop received a large number of quality submissions
from authors pursuing research in multiple disciplines,
thus making the forum truly inter-disciplinary.
There were around 20 speakers who spoke
about the dynamics on and of different systems
exhibiting a complex network structure,
from biological systems, linguistic systems, and social systems
to various technological systems
like the Internet, WWW, and peer-to-peer systems.
The organizing committee has published
some of the very high quality original submissions
as an edited volume from Birkhauser, Boston
describing contemporary research position in complex networks.</p>

<p>After the success of DOOCN I,
the organizers launched Dynamics On and Of Complex Networks – II (DOOCN II),
a two days satellite workshop
of the European Conference of Complex Systems 08.
DOOCN II was held in Jerusalem, Israel, on the 18th and 19th September 2008.</p>

<p>DOOCN III was held as a satellite of ECCS 2009
in the University of Warwick, UK on 23rd and 24th of September.
In continuation, DOOCN IV was held again as a satellite of ECCS 2010
in the University Institute Lisbon, Portugal on 16th September.</p>

<p><a href="https://www.pks.mpg.de/~peruani/doocn2011/">DOOCN V</a>
was held as a satellite of ECCS 2011
in the University of Vienna on 14th – 15th September 2011.</p>

<p><a href="http://perso.uclouvain.be/jean-charles.delvenne/DOOCN2013.html">DOOCN VI</a>
took place in Barcelona, as a satellite to ECCS 2013,
and focused on Semiotic Dynamics in time-varying social media.
As DOOCN I, the other five DOOCN workshops
counted with a large number participants
and attracted prominent scientist in the field.</p>

<p><a href="http://perso.uclouvain.be/jean-charles.delvenne/DOOCN2014.html">DOOCN VII</a>,
held in Lucca as a satellite to ECCS 2014,
focused on Big Data aspects.
<a href="http://perso.uclouvain.be/jean-charles.delvenne/DOOCN2015.html">DOOCN VIII</a>
was held in Zaragoza with focus also on BigData aspects.</p>

<p>The 9th edition of <a href="http://doocnconf.wixsite.com/homepage">DOOCN</a>
was held in Amsterdam
at Conference on Complex Systems (CCS) with the theme
&ldquo;Mining and learning for complex networks&rdquo;.</p>

<p>The 2017 edition of <a href="http://doocnconf.wixsite.com/doocn2017">DOOCN</a>
was held in Indianapolis USA
in conjunction with NetSci 2017.</p>

<p>The 2018 edition of <a href="http://doocn.org/2018">DOOCN XI</a>
was held in Thessaloniki, Greece
at Conference on Complex Systems (CCS) with the theme
&ldquo;Machine learning for complex networks&rdquo;.</p>

<p>The 2019 edition of <a href="http://doocn.org/2019">DOOCN XII</a>
was held in Burlington, Vermont, USA
in conjunction with NetSci 2019 with the theme
&ldquo;Network Representation Learning&rdquo;.</p>

<h3 id="books">DOOCN Book Series</h3>

<p>
The organizing committees of the DOOCN workshop series
have published three Birkhäuser book volumes,
from selected talks from the series.
</p>
<ul>
  <li>
    <a href="https://www.springer.com/us/book/9780817647506">
    Dynamics On and Of Complex Networks:
    Applications to Biology, Computer Science, and the Social Sciences</a>
  </li>
  <li>
    <a href="https://www.springer.com/de/book/9781461467281">
    Dynamics On and Of Complex Networks, Volume 2:
    Applications to Time-Varying Dynamical Systems</a>
  </li>
  <li>
    <a href="https://www.springer.com/de/book/9783030146825">
    Dynamics On and Of Complex Networks III:
    Machine Learning and Statistical Physics Approaches</a>
  </li>
</ul>

</div>
</body>

</html>
